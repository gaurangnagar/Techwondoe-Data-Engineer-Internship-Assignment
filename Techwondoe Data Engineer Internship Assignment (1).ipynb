{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f35002",
   "metadata": {},
   "source": [
    "# Step 1:  Import all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c49957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import bs4\n",
    "import nltk\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64835a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the survey questions\n",
    "survey_questions = [\n",
    "    \"What is your age?\",\n",
    "    \"What is your gender?\",\n",
    "    \"What is your occupation?\",\n",
    "    \"What is your income level?\",\n",
    "    \"What is your education level?\",\n",
    "    \"Do you prefer cats or dogs?\",\n",
    "    \"What is your favorite color?\",\n",
    "    \"What is your favorite food?\",\n",
    "    \"What is your favorite movie?\",\n",
    "    \"What is your favorite hobby?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00059de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the survey responses\n",
    "survey_responses = [\n",
    "    \"I am 25 years old.\",\n",
    "    \"I am female.\",\n",
    "    \"I am a software engineer.\",\n",
    "    \"I earn $80,000 per year.\",\n",
    "    \"I have a Bachelor's degree in Computer Science.\",\n",
    "    \"I prefer dogs.\",\n",
    "    \"My favorite color is blue.\",\n",
    "    \"My favorite food is pizza.\",\n",
    "    \"My favorite movie is The Shawshank Redemption.\",\n",
    "    \"My favorite hobby is reading books.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4461e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NLP functions\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d09a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(response1, response2):\n",
    "    # Preprocess the responses\n",
    "    response1_counts = preprocess_text(response1)\n",
    "    response2_counts = preprocess_text(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14175e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is your age?\n",
      "Response: I am 25 years old.\n",
      "\n",
      "Question: What is your gender?\n",
      "Response: I am female.\n",
      "\n",
      "Question: What is your occupation?\n",
      "Response: I am a software engineer.\n",
      "\n",
      "Question: What is your income level?\n",
      "Response: I earn $80,000 per year.\n",
      "\n",
      "Question: What is your education level?\n",
      "Response: I have a Bachelor's degree in Computer Science.\n",
      "\n",
      "Question: Do you prefer cats or dogs?\n",
      "Response: I prefer dogs.\n",
      "\n",
      "Question: What is your favorite color?\n",
      "Response: My favorite color is blue.\n",
      "\n",
      "Question: What is your favorite food?\n",
      "Response: My favorite food is pizza.\n",
      "\n",
      "Question: What is your favorite movie?\n",
      "Response: My favorite movie is The Shawshank Redemption.\n",
      "\n",
      "Question: What is your favorite hobby?\n",
      "Response: My favorite hobby is reading books.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze the survey responses\n",
    "for i in range(len(survey_questions)):\n",
    "    question = survey_questions[i]\n",
    "    response = survey_responses[i]\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()\n",
    "\n",
    "# Compare the survey responses\n",
    "for i in range(len(survey_responses)):\n",
    "    response1 = survey_responses[i]\n",
    "    for j in range(i+1, len(survey_responses)):\n",
    "        response2 = survey_responses[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800332a",
   "metadata": {},
   "source": [
    "# Step 2: Loading 'Input.xlsx ' into DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068a8486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3        40  https://insights.blackcoffer.com/will-machine-...\n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "110     147  https://insights.blackcoffer.com/the-future-of...\n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "112     149  https://insights.blackcoffer.com/business-anal...\n",
       "113     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"/Users/goura/Downloads/Black coffer/input.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ae63c",
   "metadata": {},
   "source": [
    "# Step 3: Finding total Length / Shape / Data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8160bcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054f40c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f6b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL_ID     int64\n",
      "URL       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b10c9",
   "metadata": {},
   "source": [
    "# Step 4; The URL present in url_list are accessed by chrome and complete HTML code for said page is stored in text form and in a list. called text and according to the serial in which url was saved in url_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c056891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL present in the dataframe is copied to url_list in form of a list.\n",
    "\n",
    "url_list = [url for url in df['URL']]\n",
    "\n",
    "text = []\n",
    "for url in url_list:\n",
    "    text.append(requests.get(url,headers={ \"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 10066.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"}))\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65a1c2",
   "metadata": {},
   "source": [
    "# Step 5: The unrequired part of HTML code present in text is removed using .content,'html.parser'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4e4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    text[i] = bs4.BeautifulSoup(text[i].content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a6b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required paragraph is copied to list called articles by finding and specifying the class in HTML under which \n",
    "# the paragraph is present.\n",
    "\n",
    "articles = []\n",
    "for text in text:\n",
    "    articles.append(text.find('div', attrs = {'class':'td-post-content'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c01ef7",
   "metadata": {},
   "source": [
    "# Step 6: Articles list is checked for Null value and drop from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ac5bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "20\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(articles)):\n",
    "    if(articles[i] == None):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803cabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3 indexes at which null value were found are dropped from database to prevent error in further code.\n",
    "\n",
    "df = df.drop([df.index[7], df.index[20],df.index[107]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d14da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The null values are dropped from articles list and copied to a new list called new_article.\n",
    "\n",
    "new_article = []\n",
    "for val in articles:\n",
    "    if val != None :\n",
    "        new_article.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5479edb",
   "metadata": {},
   "source": [
    "# Step 7: The remaining data in new_article is the data required for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a265a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML code is completely removed by using \".text\" and \\n present after removing the code is replaced by space(' '). \n",
    "\n",
    "for i in range(len(new_article)):\n",
    "    new_article[i]= new_article[i].text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f86c25",
   "metadata": {},
   "source": [
    "# Step 8: A new list called stop_words is formed and the stop words provided in form of multiple text files are added to stop_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6580304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list.\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "stopWordsFile1 = '/Users/goura/Downloads/Black coffer/StopWords_Auditor.txt'\n",
    "for stop_word in open(stopWordsFile1, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile2 = '/Users/goura/Downloads/Black coffer/StopWords_Currencies.txt'\n",
    "for stop_word in open(stopWordsFile2, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile3 = '/Users/goura/Downloads/Black coffer/StopWords_Generic.txt'\n",
    "for stop_word in open(stopWordsFile3, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile4 = '/Users/goura/Downloads/Black coffer/StopWords_GenericLong.txt'\n",
    "for stop_word in open(stopWordsFile4, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile5= '/Users/goura/Downloads/Black coffer/StopWords_DatesandNumbers.txt'\n",
    "for stop_word in open(stopWordsFile5, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile6= '/Users/goura/Downloads/Black coffer/StopWords_Geographic.txt'\n",
    "for stop_word in open(stopWordsFile6, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "    \n",
    "stopWordsFile7= '/Users/goura/Downloads/Black coffer/StopWords_Names.txt'\n",
    "for stop_word in open(stopWordsFile7, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It saves the different number of sentences present in differet paragraphs present in new_article list. \n",
    "# The number of sentences is further saved in a new list called sentences.  \n",
    "\n",
    "sentences = []\n",
    "for article in new_article:\n",
    "    sentences.append(len(sent_tokenize(article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3c601be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_articles = [' ']*len(new_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a3d88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markings such as '?', '.',',' and '!' are replaced with space(' '). \n",
    "\n",
    "for i in range(len(new_article)):\n",
    "    for w in stop_words:\n",
    "        cleaned_articles[i]= new_article[i].replace('?',' ').replace('.',' ').replace(',',' ').replace('!',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719ebd1",
   "metadata": {},
   "source": [
    "# Step 9: A new list called words is created and number of words present in the differet paragraphs is present in new_article list\n",
    "# is saved into the words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5603a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for article in new_article:\n",
    "    words.append(len(word_tokenize(article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c0a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new list called words_cleaned is used to store number of words from cleaned_articles.\n",
    "\n",
    "words_cleaned = []\n",
    "for article in cleaned_articles:\n",
    "    words_cleaned.append(len(word_tokenize(article)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d409c88",
   "metadata": {},
   "source": [
    "# Step 10: Positive words and negative words are copied from positive-words.txt and negative-words.txt respectively and \n",
    "# stored in new lists called positive_words and negative_words respectively. Further positive score and negative\n",
    "# score are calculated by finding postive words and negative words in respectively in the cleaned_article list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91657482",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "positiveWordsFile = '/Users/goura/Downloads/Black coffer/positive-words.txt'\n",
    "for positive_word in open(positiveWordsFile, 'r').readlines():\n",
    "    positive_words.append(positive_word.rstrip())\n",
    "    \n",
    "positive_score = [0]*len(new_article)\n",
    "for i in range(len(new_article)):\n",
    "    for word in positive_words:\n",
    "        for letter in cleaned_articles[i].lower().split(' '):\n",
    "            if letter==word:\n",
    "                positive_score[i]+=1\n",
    "\n",
    "negativeWordsFile = '/Users/goura/Downloads/Black coffer/negative-words.txt'\n",
    "for negative_word in open(negativeWordsFile, 'r').readlines():\n",
    "    negative_words.append(negative_word.rstrip())\n",
    "    \n",
    "negative_score = [0]*len(new_article)\n",
    "for i in range(len(new_article)):\n",
    "    for word in negative_words:\n",
    "        for letter in cleaned_articles[i].lower().split(' '):\n",
    "            if letter==word:\n",
    "                negative_score[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aee19184",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cleaned = np.array(words_cleaned)\n",
    "sentences = np.array(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b1c46",
   "metadata": {},
   "source": [
    "# Step11: Start analysing according to the required objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3a0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POSITIVE SCORE'] = positive_score\n",
    "df['NEGATIVE SCORE'] = negative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2edf022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POLARITY SCORE'] = (df['POSITIVE SCORE']-df['NEGATIVE SCORE'])/ ((df['POSITIVE SCORE'] +df['NEGATIVE SCORE']) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1917ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SUBJECTIVITY SCORE'] = (df['POSITIVE SCORE'] + df['NEGATIVE SCORE'])/( (words_cleaned) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a06210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG SENTENCE LENGTH'] = np.array(words)/np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8901dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex words and syllables are counted here for calculating percentage of complex words, fog index, complex word count \n",
    "# and syllables per word.\n",
    "\n",
    "complex_words = []\n",
    "syllables_counts = []\n",
    "for article in new_article:\n",
    "    syllables_count = 0\n",
    "    d=article.split()\n",
    "    ans=0\n",
    "    for word in d:\n",
    "        count=0\n",
    "        for i in range(len(word)):\n",
    "            if(word[i]=='a' or word[i]=='e' or word[i] =='i' or word[i] == 'o' or word[i] == 'u'):\n",
    "                count+=1\n",
    "            if(i==len(word)-2 and (word[i]=='e' and word[i+1]=='d')):\n",
    "                count-=1\n",
    "            if(i==len(word)-2 and (word[i]=='e' and word[i]=='s')):\n",
    "                count-=1\n",
    "        syllables_count+=count   \n",
    "        if(count>2):\n",
    "            ans+=1\n",
    "    syllables_counts.append(syllables_count)\n",
    "    complex_words.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05e98d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERCENTAGE OF COMPLEX WORDS'] = np.array(complex_words)/np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3155e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FOG INDEX'] = 0.4 * (df['AVG SENTENCE LENGTH'] + df['PERCENTAGE OF COMPLEX WORDS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e4361d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG NUMBER OF WORDS PER SENTENCES'] = df['AVG SENTENCE LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0da3d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COMPLEX WORD COUNT'] = complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e4dd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WORD COUNT'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "962fff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SYLLABLE PER WORD'] = np.array(syllables_counts)/np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a386ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of characters are calculated for every paragraph and stored in list called total_characters.\n",
    "\n",
    "total_characters = []\n",
    "for article in new_article:\n",
    "    characters = 0\n",
    "    for word in article.split():\n",
    "        characters+=len(word)\n",
    "    total_characters.append(characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0246b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of personal noun are counted and stored in a list called personal_nouns.\n",
    "\n",
    "personal_nouns = []\n",
    "personal_noun =['I', 'we','my', 'ours','and' 'us', 'We','My', 'Ours','And' 'Us'] \n",
    "for article in new_article:\n",
    "    ans=0\n",
    "    for word in article:\n",
    "        if word in personal_noun:\n",
    "            ans+=1\n",
    "    personal_nouns.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b86b790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUN'] = personal_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b2f814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG WORD LENGTH'] = np.array(total_characters)/np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328ee66",
   "metadata": {},
   "source": [
    "# Step 12: Final dataframe is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f14a617e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCES</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUN</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>26.129870</td>\n",
       "      <td>0.301193</td>\n",
       "      <td>10.572425</td>\n",
       "      <td>26.129870</td>\n",
       "      <td>606</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.859841</td>\n",
       "      <td>39</td>\n",
       "      <td>5.160040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>0.195493</td>\n",
       "      <td>8.288197</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>321</td>\n",
       "      <td>1642</td>\n",
       "      <td>1.542631</td>\n",
       "      <td>37</td>\n",
       "      <td>4.302680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.064479</td>\n",
       "      <td>22.552941</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>9.132809</td>\n",
       "      <td>22.552941</td>\n",
       "      <td>535</td>\n",
       "      <td>1917</td>\n",
       "      <td>1.811163</td>\n",
       "      <td>31</td>\n",
       "      <td>4.912363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.067146</td>\n",
       "      <td>19.284211</td>\n",
       "      <td>0.199782</td>\n",
       "      <td>7.793597</td>\n",
       "      <td>19.284211</td>\n",
       "      <td>366</td>\n",
       "      <td>1832</td>\n",
       "      <td>1.581332</td>\n",
       "      <td>74</td>\n",
       "      <td>4.428493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>25.050633</td>\n",
       "      <td>0.210207</td>\n",
       "      <td>10.104336</td>\n",
       "      <td>25.050633</td>\n",
       "      <td>416</td>\n",
       "      <td>1979</td>\n",
       "      <td>1.643759</td>\n",
       "      <td>36</td>\n",
       "      <td>4.612936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>20.673469</td>\n",
       "      <td>0.237907</td>\n",
       "      <td>8.364551</td>\n",
       "      <td>20.673469</td>\n",
       "      <td>241</td>\n",
       "      <td>1013</td>\n",
       "      <td>1.714709</td>\n",
       "      <td>15</td>\n",
       "      <td>4.950642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>28.451613</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>11.474976</td>\n",
       "      <td>28.451613</td>\n",
       "      <td>416</td>\n",
       "      <td>1764</td>\n",
       "      <td>1.641723</td>\n",
       "      <td>42</td>\n",
       "      <td>4.667234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.179487</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>7.960718</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>344</td>\n",
       "      <td>1296</td>\n",
       "      <td>1.711420</td>\n",
       "      <td>20</td>\n",
       "      <td>4.658179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054201</td>\n",
       "      <td>27.275862</td>\n",
       "      <td>0.294564</td>\n",
       "      <td>11.028170</td>\n",
       "      <td>27.275862</td>\n",
       "      <td>233</td>\n",
       "      <td>791</td>\n",
       "      <td>1.895070</td>\n",
       "      <td>8</td>\n",
       "      <td>5.260430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.084050</td>\n",
       "      <td>17.424242</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>7.061175</td>\n",
       "      <td>17.424242</td>\n",
       "      <td>263</td>\n",
       "      <td>1150</td>\n",
       "      <td>1.733913</td>\n",
       "      <td>8</td>\n",
       "      <td>4.673043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                76              34        0.381818            0.060011   \n",
       "1                71              38        0.302752            0.074863   \n",
       "2                74              38        0.321429            0.064479   \n",
       "3                84              28        0.500000            0.067146   \n",
       "4                69              28        0.422680            0.053151   \n",
       "..              ...             ...             ...                 ...   \n",
       "109              28              27        0.018182            0.058761   \n",
       "110              46              16        0.483871            0.037148   \n",
       "111              32              46       -0.179487            0.065217   \n",
       "112              36               4        0.800000            0.054201   \n",
       "113              47              41        0.068182            0.084050   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0              26.129870                     0.301193  10.572425   \n",
       "1              20.525000                     0.195493   8.288197   \n",
       "2              22.552941                     0.279082   9.132809   \n",
       "3              19.284211                     0.199782   7.793597   \n",
       "4              25.050633                     0.210207  10.104336   \n",
       "..                   ...                          ...        ...   \n",
       "109            20.673469                     0.237907   8.364551   \n",
       "110            28.451613                     0.235828  11.474976   \n",
       "111            19.636364                     0.265432   7.960718   \n",
       "112            27.275862                     0.294564  11.028170   \n",
       "113            17.424242                     0.228696   7.061175   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCES  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                            26.129870                 606        2012   \n",
       "1                            20.525000                 321        1642   \n",
       "2                            22.552941                 535        1917   \n",
       "3                            19.284211                 366        1832   \n",
       "4                            25.050633                 416        1979   \n",
       "..                                 ...                 ...         ...   \n",
       "109                          20.673469                 241        1013   \n",
       "110                          28.451613                 416        1764   \n",
       "111                          19.636364                 344        1296   \n",
       "112                          27.275862                 233         791   \n",
       "113                          17.424242                 263        1150   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUN  AVG WORD LENGTH  \n",
       "0             1.859841                39         5.160040  \n",
       "1             1.542631                37         4.302680  \n",
       "2             1.811163                31         4.912363  \n",
       "3             1.581332                74         4.428493  \n",
       "4             1.643759                36         4.612936  \n",
       "..                 ...               ...              ...  \n",
       "109           1.714709                15         4.950642  \n",
       "110           1.641723                42         4.667234  \n",
       "111           1.711420                20         4.658179  \n",
       "112           1.895070                 8         5.260430  \n",
       "113           1.733913                 8         4.673043  \n",
       "\n",
       "[111 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a830ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe prepared is stored in a CSV file called ASSIGNMENT SOLUTION.csv. \n",
    "\n",
    "df.to_csv('ASSIGNMENT SOLUTION.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
